{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Rafael dos Santos\n",
    "\n",
    "## José Antônio Bechara\n",
    "\n",
    "## Arthur Alegro de Oliveira\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema:\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter as frequence_counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrando banco de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A filtragem do banco de dados foi feita da seguinte forma:\n",
    "\n",
    "* Converter todas as letras em minúsculas (evita de termos contagem de duas palavras iguais em significado mas escritas diferentemente. Ex.: \"casa\" e \"Casa\")\n",
    "* Manter somente letras e números (elimina quaisquer outros valores tais como caracteres especiais, pontuações, emojis, etc)\n",
    "\n",
    "\n",
    "Note que a filtragem foi feita antes da separação entre base de teste e de treinamento por conveniência, uma vez que a filtragem teria que ser feita em ambas futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def database_cleaner(dataframe, column, export=False):\n",
    "    \n",
    "    # Alphanumerics symbols:\n",
    "    alpha_numerics = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "                      'v', 'w', 'x', 'y', 'z', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', ' ']\n",
    "    \n",
    "    comments_list = []\n",
    "    \n",
    "    # Reading all comments in a dataframe's column:\n",
    "    for comment in dataframe[column]:\n",
    "        # Converting all letters to lowercase:\n",
    "        comment = comment.lower()\n",
    "        # Selecting only alphanumeric characters:\n",
    "        char_list = [char for char in comment if char in alpha_numerics]\n",
    "        # Generating clean comment:\n",
    "        clean_comment = ''.join(char_list)\n",
    "        \n",
    "        #clean_comment_stem = [stemmer.stem(word) for word in clean_comment]\n",
    "        \n",
    "        #final_comment = '.'\n",
    "        \n",
    "        #comments_list.append(clean_comment_stemizados)\n",
    "        comments_list.append(clean_comment)\n",
    "        \n",
    "    # Overwriting dataframe column with clean comments:\n",
    "    dataframe[column] = comments_list\n",
    "    \n",
    "    # Exportation control:\n",
    "    if export == False:\n",
    "        return dataframe\n",
    "    elif export == True:\n",
    "        dataframe.to_excel('clean-spamham2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Email Class\n",
       "0  go until jurong point crazy available only in ...   ham\n",
       "1                            ok lar joking wif u oni   ham\n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  spam\n",
       "3        u dun say so early hor u c already then say   ham\n",
       "4  nah i dont think he goes to usf he lives aroun...   ham"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_cleaner(pd.read_excel('spamham2019.xlsx'), 'Email', export=True)\n",
    "clean_df = pd.read_excel('clean-spamham2019.xlsx')\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando:     \n",
    "* 75% dos dados para a parte Treinamento\n",
    "* 25% dos dados para a parte Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def database_separator(database, test_size):\n",
    "    # Database separation:\n",
    "    training_data, testing_data = train_test_split(database, test_size=test_size)\n",
    "    # Percentage variables:\n",
    "    training_size = len(training_data)\n",
    "    training_percent = round( (len(training_data)/len(database))*100, 3)\n",
    "    testing_size = len(testing_data)\n",
    "    testing_percent = round( (len(testing_data)/len(database))*100, 3)\n",
    "    training_percent_spam = round(len(training_data.loc[training_data[\"Class\"]=='spam'])/ len(clean_df)*100, 3)\n",
    "    training_percent_spam_c = round(len(training_data.loc[training_data[\"Class\"]=='ham'])/ len(clean_df)*100, 3)\n",
    "    # Shows the separation's absolute and relative values:\n",
    "    print(\"Training Size: {} ({} %)\\nTest Size: {} ({} %)\\nTotal Size: {} (100 %)\\n\".format(training_size, training_percent, testing_size, testing_percent, len(database)))\n",
    "    print(\"Training Partials: {} % SPAM + {} % HAM\".format(training_percent_spam, training_percent_spam_c))\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 4179 (75.0 %)\n",
      "Test Size: 1393 (25.0 %)\n",
      "Total Size: 5572 (100 %)\n",
      "\n",
      "Training Partials: 10.176 % SPAM + 64.824 % HAM\n"
     ]
    }
   ],
   "source": [
    "training_data, testing_data = database_separator(pd.read_excel('clean-spamham2019.xlsx'), test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando somente as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM words: 13438\n",
      "HAM words: 49982\n"
     ]
    }
   ],
   "source": [
    "spam_words = [word  for comment in (training_data[training_data['Class'] == 'spam']['Email']) for word in comment.split(' ') if word != \"\"]\n",
    "ham_words = [word for comment in (training_data[training_data['Class'] == 'ham']['Email']) for word in comment.split(' ') if word != \"\"]\n",
    "all_words = spam_words + spam_c_words\n",
    "\n",
    "spam_freq = frequence_counter(spam_words)\n",
    "ham_freq = frequence_counter(ham_words)\n",
    "\n",
    "print(\"SPAM words: {}\\nHAM words: {}\".format(len(spam_words), len(ham_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabendo que todas as mensagens são necessariamente e somente SPAM ou HAM,  podemos dizer que suas probabilidades são complementares. Portanto:\n",
    "\n",
    "$$ SPAM + HAM\\space=\\space Total$$\n",
    "\n",
    "$$P(SPAM) + P(HAM)\\space=\\space 1$$\n",
    "\n",
    "Assim a temos que:\n",
    "\n",
    "$$P(SPAM)=\\frac{SPAM}{Total}$$\n",
    "\n",
    "$$P(HAM)=\\frac{HAM}{Total}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_SPAM(spam_words, all_words):\n",
    "    return len(spam_words)/len(all_words)\n",
    "\n",
    "def P_HAM(ham_words, all_words):\n",
    "    return len(ham_words)/len(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo o Teorema de Bayes, temos que:\n",
    "\n",
    "$$P(A|B)\\space=\\space\\frac{P(B|A)\\cdot P(A)}{P(B)}$$\n",
    "\n",
    "Portanto temos que:\n",
    "\n",
    "$$P(SPAM|message)\\space=\\space\\frac{P(message|SPAM)\\cdot P(SPAM)}{P(message)}$$\n",
    "\n",
    "$$P(HAM|message)\\space=\\space\\frac{P(message|HAM)\\cdot P(HAM)}{P(message)}$$\n",
    "\n",
    "Considerando que o classificação consiste em saber qual probabilidade é maior (de ser SPAM ou HAM), basta dividir ambas as equações:\n",
    "\n",
    "$$Class\\space=\\space\\frac{P(SPAM|message)}{P(HAM|message)}\\space=\\space \\frac{\\frac{P(message|SPAM)\\cdot P(SPAM)}{P(message)}}{\\frac{P(message|HAM)\\cdot P(HAM)}{P(message)}}\\space=\\space \\frac{P(message|SPAM)\\cdot P(SPAM)}{P(message|HAM)\\cdot P(HAM)}$$\n",
    "\n",
    "Com isso, eliminamos a variável $P(message)$ e, além disso, torna-se muito mais fácil a classificação, basta comparar se o resultado é maior ou menor que 0.\n",
    "\n",
    "Note que se a probabilidade de ser SPAM é maior do que ser HAM, ou seja, se $P(message|SPAM) > P(message|HAM)$ o resultado será maior do que 0; caso contrário, ou seja, se $P(message|SPAM) < P(message|HAM)$ o resultado será menor do que 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(messagem, spam_words, ham_words, all_words):\n",
    "    P_SPAM_message = P_message_SPAM()*P_SPAM(spam_words, all_words)\n",
    "    P_HAM_message = P_message_HAM()*P_HAM(ham_words, all_words)\n",
    "    if P_SPAM_message > P_HAM_message:\n",
    "        return \"SPAM\"\n",
    "    elif P_SPAM_message < P_HAM_message:\n",
    "        return \"HAM\"\n",
    "    else:\n",
    "        return \"-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contribuição de Naive vem a seguir: Assumir que todas as palavras de uma mesma mensagem sejam independentes entre si. Isso significa que a a mensagem nada mais é do que um conjunto de palavras (implicando também que a ordem dessas palavras é irrelevante). Em termos matemáticos podemos dizer que:\n",
    "\n",
    "$$P(message)\\space=\\space\\sum^{\\infty}_{n=1} P(word_n)$$\n",
    "\n",
    "Assim sendo podemos reescrever as equações obtidas anteriormente da seguinte forma:\n",
    "\n",
    "$$P(message|SPAM)\\space=\\space\\sum^{\\infty}_{n=1} P(word_n|SPAM)$$\n",
    "\n",
    "$$P(message|HAM)\\space=\\space\\sum^{\\infty}_{n=1} P(word_n|HAM)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_word_SPAM(word):\n",
    "    return spam_freq[word]/len(all_words)\n",
    "\n",
    "def P_word_HAM(word):\n",
    "    return ham_freq[word]/len(all_words)\n",
    "\n",
    "message_words = [word for word in message.split('') if != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naive_bayes_classifier():\n",
    "    __init__():\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
