{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ciência dos Dados - PROJETO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Rafael dos Santos\n",
    "\n",
    "## José Antônio Bechara\n",
    "\n",
    "## Arthur Alegro de Oliveira\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## 1. Problema\n",
    "\n",
    "O Classificador Naive-Bayes, o qual se baseia no uso do teorema de Bayes, é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser SPAM considerando as palavras em seu conteúdo e, de forma complementar, permite calcular a probabilidade de uma mensagem ser HAM dada as palavras descritas na mensagem.\n",
    "\n",
    "Para realizar o MVP (minimum viable product) do projeto, você precisa programar uma versão do classificador que \"aprende\" o que é uma mensagem SPAM considerando uma base de treinamento e comparar o desempenho dos resultados com uma base de testes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Separação da base de dados em Treinamento e Teste\n",
    "\n",
    "A base de dados deve ser separada em duas partes, aleatoriamente, considerando: \n",
    "    \n",
    "    75% dos dados para a parte Treinamento; e\n",
    "    25% dos dados para a parte Teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner_not_alphanumeric(dataframe, column, export=False):\n",
    "    \n",
    "    # Alphanumerics symbols:\n",
    "    alpha_numerics = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "                      'v', 'w', 'x', 'y', 'z', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', ' ']\n",
    "    \n",
    "    comments_list = []\n",
    "    \n",
    "    # Reading all comments in a dataframe's column:\n",
    "    for comment in dataframe[column]:\n",
    "        comment = comment.lower()\n",
    "        # Selecting only alphanumeric characters:\n",
    "        char_list = [char for char in comment if char in alpha_numerics]\n",
    "        # Generating clean comment:\n",
    "        clean_comment = ''.join(char_list)\n",
    "        \n",
    "        clean_comment_stemizados = [stemmer.stem(palavra) for palavra in clean_comment]\n",
    "        comments_list.append(clean_comment_stemizados)\n",
    "                          \n",
    "    dataframe[column] = comments_list\n",
    "    \n",
    "    if export == False:\n",
    "        return dataframe\n",
    "    elif export == True:\n",
    "        dataframe.to_excel(\"nome.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"spamham2019.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaner_not_alphanumeric(data, \"Email\", export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = train_test_split(pd.read_excel('nome.xlsx'), test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_percentile_not_spam = len(training_data.loc[training_data[\"Class\"]=='ham'])/ len(data)\n",
    "training_percentile_spam = 1 - training_percentile_not_spam\n",
    "total_training = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words_spam = []\n",
    "list_words_not_spam = []\n",
    "\n",
    "spam_frequency = {}\n",
    "not_spam_frequency = {}\n",
    "\n",
    "i = 0\n",
    "for email in testing_data:\n",
    "    for word in email:\n",
    "        if list(testing_data[\"Class\"])[i] == \"spam\":\n",
    "            if word not in list_words_spam:\n",
    "                list_words_spam.append(word)\n",
    "                spam_frequency[word] = 1\n",
    "            else:\n",
    "                spam_frequency[word] += 1\n",
    "        else:\n",
    "            if word not in list_words_not_spam:\n",
    "                list_words_not_spam.append(word)\n",
    "                not_spam_frequency[word] = 1\n",
    "            else:\n",
    "                not_spam_frequency[word] += 1\n",
    "        i += 1\n",
    "        \n",
    "total_words = len(list_words_not_spam) + len(list_words_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(email, dic_words, n_total_words_in_email, prob_a):\n",
    "    P_b_dado_a = prob_a\n",
    "    \n",
    "    for word in email:\n",
    "        ocurrence = 1\n",
    "        if word in dic_palavras:\n",
    "            ocorrencia += dic_words[word]\n",
    "        p_a_dado_b = ocorrencia / (n_total_words_in_email+total_words)\n",
    "    \n",
    "    return p_a_dado_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparador_prob(prob_0, prob_1):\n",
    "    if prob_0 > prob_1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Qualidade do Classificador alterando a base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
